Отчет о производительности модели
Результаты матрицы ошибок

ResNetCNN (MNIST): Высокая точность с большинством предсказаний вдоль диагонали.
RegularizedResNetCIFAR (CIFAR10): Улучшенная классификация с уменьшенным количеством ошибок вне диагонали.
FullyConnected (MNIST): Сильная диагональ, но с некоторыми ошибками классификации.
DeepFullyConnected (MNIST): Повышенная точность с заметными значениями вне диагонали.
SimpleCNN (MNIST): Отличная точность с доминированием диагонали в матрице ошибок.


ResNetCNN: Постепенное снижение потерь, с улучшением точности по эпохам.
RegularizedResNetCIFAR: Более плавные кривые потерь и точности, указывающие на лучшую регуляризацию.
FullyConnected: Быстрое снижение потерь, но с некоторыми колебаниями тестовых потерь.
DeepFullyConnected: Постоянный рост точности с небольшим увеличением тестовых потерь.
SimpleCNN: Низкие потери и высокая точность на MNIST с минимальными колебаниями.

Дополнительные метрики

MNIST (False):
Потери на обучении: 0.0069
Потери на тесте: 0.0532
Точность на обучении: 99.78%
Точность на тесте: 98.87%
Среднее время обучения на эпоху: 22.38с
Среднее время вывода на эпоху: 2.45с
Общее количество параметров: 274442
Финальная норма градиента: 0.0805


CIFAR-10:
DeepFullyConnected:
Потери на обучении: 0.2724
Потери на тесте: 2.5158
Точность на обучении: 90.46%
Точность на тесте: 54.04%
Среднее время обучения на эпоху: 16.34с
Среднее время вывода на эпоху: 2.04с
Общее количество параметров: 3837066
Финальная норма градиента: 1.9518
Переобучение (разница точности обучения и теста): 36.42%


ResNetCIFAR:
Потери на обучении: 0.0987
Потери на тесте: 1.3981
Точность на обучении: 96.54%
Точность на тесте: 71.66%
Среднее время обучения на эпоху: 22.57с
Среднее время вывода на эпоху: 2.97с
Общее количество параметров: 313994
Финальная норма градиента: 3.4536
Переобучение (разница точности обучения и теста): 24.88%


RegularizedResNetCIFAR:
Потери на обучении: 0.3411
Потери на тесте: 0.8687
Точность на обучении: 87.71%
Точность на тесте: 70.80%
Среднее время обучения на эпоху: 23.43с
Среднее время вывода на эпоху: 2.96с
Общее количество параметров: 313994
Финальная норма градиента: 4.2282
Переобучение (разница точности обучения и теста): 16.91%





Проведенная работа
провел детальный анализ различных архитектур нейронных сетей на наборах данных MNIST и CIFAR10. Это включало генерацию и интерпретацию матриц ошибок для оценки производительности классификации по различным классам. Также были построены кривые обучения для отслеживания прогресса потерь и точности на обучении и тестировании по нескольким эпохам. Целью было сравнить эффективность различных моделей и определить направления для улучшения.
Визуализации

Матрица ошибок для ResNetCNN на MNIST
Кривая обучения для RegularizedResNetCIFAR на CIFAR10
Матрица ошибок для ResNetCIFAR на CIFAR10
Матрица ошибок для RegularizedResNetCIFAR на CIFAR10
Матрица ошибок для SimpleCNN на MNIST
Кривая обучения для SimpleCNN на MNIST

Выводы

Модель ResNetCNN хорошо работает на MNIST, с высоким доминированием диагонали в матрице ошибок, что указывает на хорошую точность классификации.
RegularizedResNetCIFAR демонстрирует улучшенную стабильность и сходимость на CIFAR10, что видно по более плавным кривым потерь и точности.
Модель FullyConnected достигает высокой точности на MNIST, но показывает признаки переобучения из-за вариаций тестовых потерь.
DeepFullyConnected улучшает точность на MNIST, однако дальнейшая регуляризация может устранить рост тестовых потерь.
SimpleCNN показывает выдающуюся производительность на MNIST с высокой точностью и минимальными ошибками.
DeepFullyConnected на CIFAR-10 демонстрирует значительное переобучение, что видно по большой разнице в точности обучения и теста.
ResNetCIFAR улучшает обобщающую способность по сравнению с DeepFullyConnected, хотя все еще показывает некоторые признаки переобучения.
RegularizedResNetCIFAR показывает наилучшую обобщающую способность на CIFAR-10 с наименьшей разницей в точности обучения и теста.
Анализ подчеркивает важность применения техник регуляризации для улучшения производительности модели и снижения переобучения.
